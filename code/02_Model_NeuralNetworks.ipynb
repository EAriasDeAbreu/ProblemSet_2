{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24fc84be940f47ccb4d456852ec88792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e96b276564043bba3c1fc2b855fade1",
              "IPY_MODEL_189708a61c1f470487037daf53e0623d"
            ],
            "layout": "IPY_MODEL_249f06f08a1a4360b43178ec215745d5"
          }
        },
        "6e96b276564043bba3c1fc2b855fade1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ded89f2a7d4ab6bf85ecbdacce2510",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_75415b308c2646b0b2350f71052f672c",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "189708a61c1f470487037daf53e0623d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a05331690e24a7ca98892fb7d22c268",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ef47c9b4cc9454da6ab63714767bd03",
            "value": 1
          }
        },
        "249f06f08a1a4360b43178ec215745d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ded89f2a7d4ab6bf85ecbdacce2510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75415b308c2646b0b2350f71052f672c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a05331690e24a7ca98892fb7d22c268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef47c9b4cc9454da6ab63714767bd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2mcbjRntPm",
        "outputId": "29bb6f0f-a308-4616-b0de-cb058fa11271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb # for model tuning via weights and biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ycOsPVtn_xE",
        "outputId": "147cfafb-f485-4dff-f95c-6ea3e1e6d3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.16.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import wandb\n",
        "import random\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "qIYYxspqn0b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# device-agnostic code\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "iqCgRN4ooCgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Loading & Augmentation"
      ],
      "metadata": {
        "id": "UpsP3jWOoFtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train = pd.read_csv('/content/drive/MyDrive/BDML-2024/P-Set2/data/imputed_no_missings/train_ready.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/BDML-2024/P-Set2/data/imputed_no_missings/test_ready.csv')\n",
        "\n",
        "train.shape, test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2elQWMUoEzz",
        "outputId": "1e557bf4-8297-4f1a-c309-21267d7efa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((164960, 49), (66168, 42))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32SW9WeczPhs",
        "outputId": "74f341cd-30e5-44cd-8e37-4584296e2141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'Clase', 'Dominio', 'P5000', 'P5010', 'P5090', 'Nper', 'Npersug',\n",
              "       'Ingtotug', 'Ingtotugarr', 'Ingpcug', 'Li', 'Lp', 'Pobre', 'Indigente',\n",
              "       'Npobres', 'Nindigentes', 'Fex_c', 'Depto', 'Fex_dpto',\n",
              "       'mean_age_household', 'has_social_program', 'educ_attainment',\n",
              "       'P6240_someone_works', 'P6240_unemployment_rate',\n",
              "       'P6240_main_household_activity', 'P6240_activity_diversity',\n",
              "       'has_food_subsidy', 'has_transport_subsidy', 'has_family_subsidy',\n",
              "       'has_school_subsidy', 'total_subsidies', 'has_pension_contributor',\n",
              "       'has_pensioner', 'prop_pension_contributors', 'prop_pensioners',\n",
              "       'pension_status', 'household_size', 'dependency_ratio',\n",
              "       'is_female_headed', 'has_health_insurance', 'main_insurance_type',\n",
              "       'insurance_coverage_rate', 'num_individuals', 'num_under_18',\n",
              "       'num_over_65', 'has_over_65', 'has_university_education',\n",
              "       'receives_food_payment'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = [\n",
        "    'Dominio', 'P6240_someone_works', 'pension_status', 'is_female_headed', 'has_health_insurance',\n",
        "    'Clase', 'has_social_program', 'educ_attainment', 'P6240_main_household_activity',\n",
        "    'has_food_subsidy', 'has_transport_subsidy', 'has_family_subsidy',\n",
        "    'has_school_subsidy', 'has_pension_contributor', 'has_pensioner',\n",
        "    'main_insurance_type', 'has_university_education', 'receives_food_payment'\n",
        "]\n",
        "\n",
        "numeric_features = [\n",
        "    'P5000', 'P5010', 'P5090', 'Nper', 'Npersug', 'Li', 'Lp', 'Fex_c', 'Depto', 'Fex_dpto',\n",
        "    'mean_age_household', 'P6240_unemployment_rate', 'P6240_activity_diversity',\n",
        "    'total_subsidies', 'prop_pension_contributors', 'prop_pensioners', 'household_size',\n",
        "    'dependency_ratio', 'insurance_coverage_rate', 'num_individuals', 'num_under_18',\n",
        "    'num_over_65', 'has_over_65'\n",
        "]"
      ],
      "metadata": {
        "id": "Ncvfuuzvzba4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preprocessor(numeric_features, categorical_features):\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    return preprocessor"
      ],
      "metadata": {
        "id": "sY3RXq4i0Hmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import issparse, csr_matrix\n",
        "\n",
        "class SparseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, features, labels=None):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.FloatTensor(self.features[idx].toarray().squeeze()) if issparse(self.features) else torch.FloatTensor(self.features[idx])\n",
        "        if self.labels is not None:\n",
        "            y = torch.LongTensor([self.labels[idx]]).squeeze()\n",
        "            return x, y\n",
        "        return x"
      ],
      "metadata": {
        "id": "O0r7nCGX6lLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset & Model Definition"
      ],
      "metadata": {
        "id": "794EjoNcoih8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HouseholdDataset(Dataset):\n",
        "    def __init__(self, features, labels=None):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        if labels is not None:\n",
        "            self.labels = torch.LongTensor(labels)\n",
        "        else:\n",
        "            self.labels = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "            return self.features[idx], self.labels[idx]\n",
        "        else:\n",
        "            return self.features[idx]\n",
        "\n",
        "class PovertyPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, dropout):\n",
        "        super(PovertyPredictor, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size1),\n",
        "            nn.BatchNorm1d(hidden_size1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size1, hidden_size2),\n",
        "            nn.BatchNorm1d(hidden_size2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size2, hidden_size3),\n",
        "            nn.BatchNorm1d(hidden_size3),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size3, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "zOQmhRBDolEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Training & Eval Functions"
      ],
      "metadata": {
        "id": "5mUZ4CBgoonQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=100, patience=10):\n",
        "    best_model = None\n",
        "    best_val_f1 = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        val_f1 = evaluate_model(model, val_loader, device)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            epochs_no_improve = 0\n",
        "            best_model = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print(\"Early stopping!\")\n",
        "                model.load_state_dict(best_model)\n",
        "                return model, best_val_f1\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return model, best_val_f1\n",
        "\n",
        "def make_predictions(model, X, device):\n",
        "    model.eval()\n",
        "    dataset = SparseDataset(X)\n",
        "    dataloader = DataLoader(dataset, batch_size=32)\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features in dataloader:\n",
        "            features = features.to(device)\n",
        "            outputs = model(features)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds)"
      ],
      "metadata": {
        "id": "dTP36TEkonFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for features, labels in data_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return f1_score(all_labels, all_preds)"
      ],
      "metadata": {
        "id": "Ku2HOG4dG-bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Base Model Training\n",
        "(Un-tunned)"
      ],
      "metadata": {
        "id": "qGUnyvDGou07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "def train_base_model(features, labels, model_params, device):\n",
        "    print(f\"Using {len(numeric_features)} numeric features: {numeric_features}\")\n",
        "    print(f\"Using {len(categorical_features)} categorical features: {categorical_features}\")\n",
        "\n",
        "    preprocessor = create_preprocessor(numeric_features, categorical_features)\n",
        "\n",
        "    # Split data into train and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "    # Preprocess features\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "    X_val_processed = preprocessor.transform(X_val)\n",
        "\n",
        "    print(\"Original training set shape:\", Counter(y_train))\n",
        "\n",
        "    # Apply SMOTE to the training set\n",
        "    smote = SMOTE(random_state=42)\n",
        "    if issparse(X_train_processed):\n",
        "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed.toarray(), y_train)\n",
        "        X_train_resampled = csr_matrix(X_train_resampled)\n",
        "    else:\n",
        "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
        "\n",
        "    print(\"Resampled training set shape:\", Counter(y_train_resampled))\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = SparseDataset(X_train_resampled, y_train_resampled)\n",
        "    val_dataset = SparseDataset(X_val_processed, y_val.values)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=model_params['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=model_params['batch_size'])\n",
        "\n",
        "    # Initialize model, loss, and optimizer\n",
        "    input_size = X_train_resampled.shape[1]\n",
        "    model = PovertyPredictor(\n",
        "        input_size=input_size,\n",
        "        hidden_size1=model_params['hidden_size1'],\n",
        "        hidden_size2=model_params['hidden_size2'],\n",
        "        hidden_size3=model_params['hidden_size3'],\n",
        "        dropout=model_params['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=model_params['learning_rate'], weight_decay=model_params['weight_decay'])\n",
        "\n",
        "    # Train and evaluate\n",
        "    trained_model, best_val_f1 = train_model(model, train_loader, val_loader, criterion, optimizer, device,\n",
        "                                             num_epochs=model_params['num_epochs'], patience=model_params['patience'])\n",
        "\n",
        "    print(f\"Best Validation F1: {best_val_f1:.4f}\")\n",
        "\n",
        "    # Detailed evaluation on validation set\n",
        "    final_val_f1 = evaluate_model(trained_model, val_loader, device)\n",
        "    print(f\"\\nFinal Validation F1 Score: {final_val_f1:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    y_pred = make_predictions(trained_model, X_val_processed, device)\n",
        "    print(classification_report(y_val, y_pred, target_names=['Not Poor', 'Poor']))\n",
        "\n",
        "    return trained_model, preprocessor, best_val_f1\n",
        "\n",
        "# Modify the make_predictions function to work with sparse data\n",
        "def make_predictions(model, X, preprocessor, device):\n",
        "    model.eval()\n",
        "    # Preprocess the features\n",
        "    X_processed = preprocessor.transform(X)\n",
        "\n",
        "    dataset = SparseDataset(X_processed)\n",
        "    dataloader = DataLoader(dataset, batch_size=32)\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features in dataloader:\n",
        "            features = features.to(device)\n",
        "            outputs = model(features)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds)\n",
        "\n",
        "def format_predictions(test_df, predictions):\n",
        "    # Create a new DataFrame with 'id' and 'pobre' columns\n",
        "    result_df = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'pobre': predictions\n",
        "    })\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "nDK43zK0ot2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_params = {\n",
        "    'batch_size': 32,\n",
        "    'hidden_size1': 128,\n",
        "    'hidden_size2': 64,\n",
        "    'hidden_size3': 32,\n",
        "    'dropout': 0.3,\n",
        "    'learning_rate': 1e-4,\n",
        "    'weight_decay': 1e-5,\n",
        "    'num_epochs': 100,\n",
        "    'patience': 10\n",
        "}\n",
        "\n",
        "features = train.drop(['Pobre', 'id'], axis=1)\n",
        "labels = train['Pobre']\n",
        "best_model, best_preprocessor, best_f1 = train_base_model(features, labels, model_params, device)\n",
        "print(f\"Best Overall Validation F1 Score: {best_f1:.4f}\")"
      ],
      "metadata": {
        "id": "zaCBvvi6q_Zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516dbe7b-2af4-442a-d1c8-915d2ed21592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 23 numeric features: ['P5000', 'P5010', 'P5090', 'Nper', 'Npersug', 'Li', 'Lp', 'Fex_c', 'Depto', 'Fex_dpto', 'mean_age_household', 'P6240_unemployment_rate', 'P6240_activity_diversity', 'total_subsidies', 'prop_pension_contributors', 'prop_pensioners', 'household_size', 'dependency_ratio', 'insurance_coverage_rate', 'num_individuals', 'num_under_18', 'num_over_65', 'has_over_65']\n",
            "Using 18 categorical features: ['Dominio', 'P6240_someone_works', 'pension_status', 'is_female_headed', 'has_health_insurance', 'Clase', 'has_social_program', 'educ_attainment', 'P6240_main_household_activity', 'has_food_subsidy', 'has_transport_subsidy', 'has_family_subsidy', 'has_school_subsidy', 'has_pension_contributor', 'has_pensioner', 'main_insurance_type', 'has_university_education', 'receives_food_payment']\n",
            "Original training set shape: Counter({0: 105549, 1: 26419})\n",
            "Resampled training set shape: Counter({1: 105549, 0: 105549})\n",
            "Epoch 1/100, Validation F1: 0.6290\n",
            "Epoch 2/100, Validation F1: 0.6336\n",
            "Epoch 3/100, Validation F1: 0.6477\n",
            "Epoch 4/100, Validation F1: 0.6549\n",
            "Epoch 5/100, Validation F1: 0.6325\n",
            "Epoch 6/100, Validation F1: 0.6397\n",
            "Epoch 7/100, Validation F1: 0.6353\n",
            "Epoch 8/100, Validation F1: 0.6471\n",
            "Epoch 9/100, Validation F1: 0.6439\n",
            "Epoch 10/100, Validation F1: 0.6428\n",
            "Epoch 11/100, Validation F1: 0.6464\n",
            "Epoch 12/100, Validation F1: 0.6461\n",
            "Epoch 13/100, Validation F1: 0.6457\n",
            "Epoch 14/100, Validation F1: 0.6422\n",
            "Early stopping!\n",
            "Best Validation F1: 0.6549\n",
            "\n",
            "Final Validation F1 Score: 0.6422\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Poor       0.95      0.81      0.87     26387\n",
            "        Poor       0.52      0.83      0.64      6605\n",
            "\n",
            "    accuracy                           0.81     32992\n",
            "   macro avg       0.74      0.82      0.76     32992\n",
            "weighted avg       0.87      0.81      0.83     32992\n",
            "\n",
            "Best Overall Validation F1 Score: 0.6549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Tuning â€“ Weights & Biases"
      ],
      "metadata": {
        "id": "gMydTyGopBfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_tuning(features, labels, sweep_config, project_name):\n",
        "    def train():\n",
        "        with wandb.init():\n",
        "            config = wandb.config\n",
        "\n",
        "            print(f\"Using {len(numeric_features)} numeric features: {numeric_features}\")\n",
        "            print(f\"Using {len(categorical_features)} categorical features: {categorical_features}\")\n",
        "\n",
        "            preprocessor = create_preprocessor(numeric_features, categorical_features)\n",
        "\n",
        "            # Split data into train and validation sets\n",
        "            X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "            # Preprocess features\n",
        "            X_train_processed = preprocessor.fit_transform(X_train)\n",
        "            X_val_processed = preprocessor.transform(X_val)\n",
        "\n",
        "            print(\"Original training set shape:\", Counter(y_train))\n",
        "\n",
        "            # Apply SMOTE to the training set\n",
        "            smote = SMOTE(random_state=42)\n",
        "            if issparse(X_train_processed):\n",
        "                X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed.toarray(), y_train)\n",
        "                X_train_resampled = csr_matrix(X_train_resampled)\n",
        "            else:\n",
        "                X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
        "\n",
        "            print(\"Resampled training set shape:\", Counter(y_train_resampled))\n",
        "\n",
        "            # Create datasets and dataloaders\n",
        "            train_dataset = SparseDataset(X_train_resampled, y_train_resampled)\n",
        "            val_dataset = SparseDataset(X_val_processed, y_val.values)\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
        "\n",
        "            # Initialize model, loss, and optimizer\n",
        "            input_size = X_train_resampled.shape[1]\n",
        "            model = PovertyPredictor(\n",
        "                input_size=input_size,\n",
        "                hidden_size1=config.hidden_size1,\n",
        "                hidden_size2=config.hidden_size2,\n",
        "                hidden_size3=config.hidden_size3,\n",
        "                dropout=config.dropout\n",
        "            ).to(device)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
        "\n",
        "            # Train and evaluate\n",
        "            trained_model, best_val_f1 = train_model(model, train_loader, val_loader, criterion, optimizer, device,\n",
        "                                                     num_epochs=config.num_epochs, patience=config.patience)\n",
        "\n",
        "            print(f\"Best Validation F1: {best_val_f1:.4f}\")\n",
        "\n",
        "            # Detailed evaluation on validation set\n",
        "            final_val_f1 = evaluate_model(trained_model, val_loader, device)\n",
        "            print(f\"\\nFinal Validation F1 Score: {final_val_f1:.4f}\")\n",
        "\n",
        "            print(\"\\nClassification Report:\")\n",
        "            y_pred = make_predictions(trained_model, X_val_processed, device)\n",
        "            print(classification_report(y_val, y_pred, target_names=['Not Poor', 'Poor']))\n",
        "\n",
        "            # Log metrics\n",
        "            wandb.log({\n",
        "                'best_val_f1': best_val_f1,\n",
        "                'final_val_f1': final_val_f1\n",
        "            })\n",
        "\n",
        "            return best_val_f1\n",
        "\n",
        "    sweep_id = wandb.sweep(sweep_config, project=project_name)\n",
        "    wandb.agent(sweep_id, function=train, count=75)\n",
        "\n",
        "# Helper function for making predictions\n",
        "def make_predictions(model, features, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        features_tensor = torch.FloatTensor(features).to(device)\n",
        "        outputs = model(features_tensor)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "    return preds.cpu().numpy()"
      ],
      "metadata": {
        "id": "GZolocbupFKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {'name': 'average_val_f1', 'goal': 'maximize'},\n",
        "    'parameters': {\n",
        "        'learning_rate': {'min': 3e-4, 'max': 1e-2},\n",
        "        'batch_size': {'values': [32, 64]},\n",
        "        'hidden_size1': {'values': [128, 256]},\n",
        "        'hidden_size2': {'values': [32, 64, 128]},\n",
        "        'hidden_size3': {'values': [16, 32, 64]},\n",
        "        'dropout': {'min': 0.1, 'max': 0.5},\n",
        "        'weight_decay': {'min': 7e-6, 'max': 1e-4},\n",
        "        'num_epochs': {'value': 100},\n",
        "        'patience': {'value': 10}\n",
        "    }\n",
        "}\n",
        "\n",
        "features = train.drop(['Pobre', 'id'], axis=1)\n",
        "labels = train['Pobre']\n",
        "wandb_tuning(features, labels, sweep_config, \"poverty-prediction-nn\")\n",
        "\n",
        "# xxxx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "24fc84be940f47ccb4d456852ec88792",
            "6e96b276564043bba3c1fc2b855fade1",
            "189708a61c1f470487037daf53e0623d",
            "249f06f08a1a4360b43178ec215745d5",
            "e9ded89f2a7d4ab6bf85ecbdacce2510",
            "75415b308c2646b0b2350f71052f672c",
            "8a05331690e24a7ca98892fb7d22c268",
            "0ef47c9b4cc9454da6ab63714767bd03"
          ]
        },
        "id": "nznYoihprZpj",
        "outputId": "5d41d42d-b431-4d87-94e6-078f5bb3a0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 0xwq0uy6\n",
            "Sweep URL: https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l80llau6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.35489683219666635\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size1: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size2: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size3: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002369832839948444\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.286923723509476e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241019_233120-l80llau6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/l80llau6' target=\"_blank\">likely-sweep-1</a></strong> to <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/l80llau6' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/l80llau6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 23 numeric features: ['P5000', 'P5010', 'P5090', 'Nper', 'Npersug', 'Li', 'Lp', 'Fex_c', 'Depto', 'Fex_dpto', 'mean_age_household', 'P6240_unemployment_rate', 'P6240_activity_diversity', 'total_subsidies', 'prop_pension_contributors', 'prop_pensioners', 'household_size', 'dependency_ratio', 'insurance_coverage_rate', 'num_individuals', 'num_under_18', 'num_over_65', 'has_over_65']\n",
            "Using 18 categorical features: ['Dominio', 'P6240_someone_works', 'pension_status', 'is_female_headed', 'has_health_insurance', 'Clase', 'has_social_program', 'educ_attainment', 'P6240_main_household_activity', 'has_food_subsidy', 'has_transport_subsidy', 'has_family_subsidy', 'has_school_subsidy', 'has_pension_contributor', 'has_pensioner', 'main_insurance_type', 'has_university_education', 'receives_food_payment']\n",
            "Original training set shape: Counter({0: 105549, 1: 26419})\n",
            "Resampled training set shape: Counter({1: 105549, 0: 105549})\n",
            "Epoch 1/100, Validation F1: 0.6393\n",
            "Epoch 2/100, Validation F1: 0.6473\n",
            "Epoch 3/100, Validation F1: 0.6342\n",
            "Epoch 4/100, Validation F1: 0.6362\n",
            "Epoch 5/100, Validation F1: 0.6407\n",
            "Epoch 6/100, Validation F1: 0.6451\n",
            "Epoch 7/100, Validation F1: 0.6306\n",
            "Epoch 8/100, Validation F1: 0.6470\n",
            "Epoch 9/100, Validation F1: 0.6422\n",
            "Epoch 10/100, Validation F1: 0.6481\n",
            "Epoch 11/100, Validation F1: 0.6478\n",
            "Epoch 12/100, Validation F1: 0.6458\n",
            "Epoch 13/100, Validation F1: 0.6541\n",
            "Epoch 14/100, Validation F1: 0.6497\n",
            "Epoch 15/100, Validation F1: 0.6581\n",
            "Epoch 16/100, Validation F1: 0.6555\n",
            "Epoch 17/100, Validation F1: 0.6390\n",
            "Epoch 18/100, Validation F1: 0.6530\n",
            "Epoch 19/100, Validation F1: 0.6437\n",
            "Epoch 20/100, Validation F1: 0.6386\n",
            "Epoch 21/100, Validation F1: 0.6515\n",
            "Epoch 22/100, Validation F1: 0.6462\n",
            "Epoch 23/100, Validation F1: 0.6609\n",
            "Epoch 24/100, Validation F1: 0.6484\n",
            "Epoch 25/100, Validation F1: 0.6357\n",
            "Epoch 26/100, Validation F1: 0.6461\n",
            "Epoch 27/100, Validation F1: 0.6472\n",
            "Epoch 28/100, Validation F1: 0.6514\n",
            "Epoch 29/100, Validation F1: 0.6469\n",
            "Epoch 30/100, Validation F1: 0.6455\n",
            "Epoch 31/100, Validation F1: 0.6427\n",
            "Epoch 32/100, Validation F1: 0.6437\n",
            "Epoch 33/100, Validation F1: 0.6485\n",
            "Early stopping!\n",
            "Best Validation F1: 0.6609\n",
            "\n",
            "Final Validation F1 Score: 0.6485\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-22-98f8402f65ca>\", line 61, in train\n",
            "    y_pred = make_predictions(trained_model, X_val_processed, device)\n",
            "  File \"<ipython-input-22-98f8402f65ca>\", line 79, in make_predictions\n",
            "    features_tensor = torch.FloatTensor(features).to(device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\", line 404, in __len__\n",
            "    raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\n",
            "TypeError: sparse array length is ambiguous; use getnnz() or shape[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.014 MB of 0.014 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24fc84be940f47ccb4d456852ec88792"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">likely-sweep-1</strong> at: <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/l80llau6' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/l80llau6</a><br/> View project at: <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241019_233120-l80llau6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run l80llau6 errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-22-98f8402f65ca>\", line 61, in train\n",
            "    y_pred = make_predictions(trained_model, X_val_processed, device)\n",
            "  File \"<ipython-input-22-98f8402f65ca>\", line 79, in make_predictions\n",
            "    features_tensor = torch.FloatTensor(features).to(device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\", line 404, in __len__\n",
            "    raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\n",
            "TypeError: sparse array length is ambiguous; use getnnz() or shape[0]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run l80llau6 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-22-98f8402f65ca>\", line 61, in train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     y_pred = make_predictions(trained_model, X_val_processed, device)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-22-98f8402f65ca>\", line 79, in make_predictions\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     features_tensor = torch.FloatTensor(features).to(device)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/_base.py\", line 404, in __len__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: sparse array length is ambiguous; use getnnz() or shape[0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qxl36b9h with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.14800436634727537\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size1: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size2: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size3: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008847194600308774\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 7.490282113083655e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241020_001121-qxl36b9h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/qxl36b9h' target=\"_blank\">earnest-sweep-2</a></strong> to <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn/sweeps/0xwq0uy6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/qxl36b9h' target=\"_blank\">https://wandb.ai/edmundo-research/poverty-prediction-nn/runs/qxl36b9h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 23 numeric features: ['P5000', 'P5010', 'P5090', 'Nper', 'Npersug', 'Li', 'Lp', 'Fex_c', 'Depto', 'Fex_dpto', 'mean_age_household', 'P6240_unemployment_rate', 'P6240_activity_diversity', 'total_subsidies', 'prop_pension_contributors', 'prop_pensioners', 'household_size', 'dependency_ratio', 'insurance_coverage_rate', 'num_individuals', 'num_under_18', 'num_over_65', 'has_over_65']\n",
            "Using 18 categorical features: ['Dominio', 'P6240_someone_works', 'pension_status', 'is_female_headed', 'has_health_insurance', 'Clase', 'has_social_program', 'educ_attainment', 'P6240_main_household_activity', 'has_food_subsidy', 'has_transport_subsidy', 'has_family_subsidy', 'has_school_subsidy', 'has_pension_contributor', 'has_pensioner', 'main_insurance_type', 'has_university_education', 'receives_food_payment']\n",
            "Original training set shape: Counter({0: 105549, 1: 26419})\n",
            "Resampled training set shape: Counter({1: 105549, 0: 105549})\n",
            "Epoch 1/100, Validation F1: 0.6376\n",
            "Epoch 2/100, Validation F1: 0.6047\n",
            "Epoch 3/100, Validation F1: 0.6360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Final Training & Prediction"
      ],
      "metadata": {
        "id": "9K0Xp2PppHH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def calculate_f1(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for features, labels in data_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return f1_score(all_labels, all_preds)\n",
        "\n",
        "def train_final_model(features, labels, best_params):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Select only numeric columns\n",
        "    numeric_columns = features.select_dtypes(include=['int64', 'float64']).columns\n",
        "    features_numeric = features[numeric_columns].values\n",
        "\n",
        "    print(f\"Selected {len(numeric_columns)} numeric features: {numeric_columns.tolist()}\")\n",
        "\n",
        "    # Split data into train and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(features_numeric, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize the model with best parameters\n",
        "    input_size = X_train.shape[1]\n",
        "    model = PovertyPredictor(\n",
        "        input_size=input_size,\n",
        "        hidden_size1=best_params['hidden_size1'],\n",
        "        hidden_size2=best_params['hidden_size2'],\n",
        "        hidden_size3=best_params['hidden_size3'],\n",
        "        dropout=best_params['dropout']\n",
        "    ).to(device)\n",
        "\n",
        "    # Prepare the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    train_dataset = HouseholdDataset(X_train_scaled, y_train.values)\n",
        "    val_dataset = HouseholdDataset(X_val_scaled, y_val.values)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'], shuffle=False)\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "    print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "    # Set up optimizer and criterion\n",
        "    optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    patience = 10\n",
        "    best_f1 = 0\n",
        "    counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(best_params['num_epochs']):\n",
        "        model.train()\n",
        "        for batch_features, batch_labels in train_loader:\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_features)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate F1 score on validation set\n",
        "        val_f1 = calculate_f1(model, val_loader, device)\n",
        "\n",
        "        # Early stopping logic\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            counter = 0\n",
        "            best_model_state = model.state_dict()\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Print epoch F1 score\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{best_params['num_epochs']}], Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Load the best model state\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model, scaler"
      ],
      "metadata": {
        "id": "NQsTC0PEpNGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage in the main script\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example usage -- silvery-sweep-19 [best_model_n16922w7]\n",
        "best_params = {\n",
        "    'batch_size': 32,\n",
        "    'hidden_size1': 256,\n",
        "    'hidden_size2': 128,\n",
        "    'hidden_size3': 32,\n",
        "    'dropout': 0.15898988565127214,\n",
        "    'learning_rate': 0.0006540550101305035,\n",
        "    'weight_decay': 0.00001273061095884153,\n",
        "    'num_epochs': 100,\n",
        "    'patience': 10\n",
        "}\n",
        "\n",
        "features = train.drop(['Pobre', 'id'], axis=1)\n",
        "labels = train['Pobre']\n",
        "best_model, best_preprocessor, best_f1 = train_base_model(features, labels, best_params, device)  # shwitched 'model_params' for 'best_params'\n",
        "print(f\"Best Overall Validation F1 Score: {best_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPJLhZqissJl",
        "outputId": "7da1ff5f-ef00-4424-d203-011f7c3b21dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 23 numeric features: ['P5000', 'P5010', 'P5090', 'Nper', 'Npersug', 'Li', 'Lp', 'Fex_c', 'Depto', 'Fex_dpto', 'mean_age_household', 'P6240_unemployment_rate', 'P6240_activity_diversity', 'total_subsidies', 'prop_pension_contributors', 'prop_pensioners', 'household_size', 'dependency_ratio', 'insurance_coverage_rate', 'num_individuals', 'num_under_18', 'num_over_65', 'has_over_65']\n",
            "Using 18 categorical features: ['Dominio', 'P6240_someone_works', 'pension_status', 'is_female_headed', 'has_health_insurance', 'Clase', 'has_social_program', 'educ_attainment', 'P6240_main_household_activity', 'has_food_subsidy', 'has_transport_subsidy', 'has_family_subsidy', 'has_school_subsidy', 'has_pension_contributor', 'has_pensioner', 'main_insurance_type', 'has_university_education', 'receives_food_payment']\n",
            "Original training set shape: Counter({0: 105549, 1: 26419})\n",
            "Resampled training set shape: Counter({1: 105549, 0: 105549})\n",
            "Epoch 1/100, Validation F1: 0.6369\n",
            "Epoch 2/100, Validation F1: 0.6458\n",
            "Epoch 3/100, Validation F1: 0.6302\n",
            "Epoch 4/100, Validation F1: 0.6403\n",
            "Epoch 5/100, Validation F1: 0.6382\n",
            "Epoch 6/100, Validation F1: 0.6528\n",
            "Epoch 7/100, Validation F1: 0.6516\n",
            "Epoch 8/100, Validation F1: 0.6497\n",
            "Epoch 9/100, Validation F1: 0.6525\n",
            "Epoch 10/100, Validation F1: 0.6496\n",
            "Epoch 11/100, Validation F1: 0.6536\n",
            "Epoch 12/100, Validation F1: 0.6444\n",
            "Epoch 13/100, Validation F1: 0.6531\n",
            "Epoch 14/100, Validation F1: 0.6386\n",
            "Epoch 15/100, Validation F1: 0.6526\n",
            "Epoch 16/100, Validation F1: 0.6542\n",
            "Epoch 17/100, Validation F1: 0.6500\n",
            "Epoch 18/100, Validation F1: 0.6541\n",
            "Epoch 19/100, Validation F1: 0.6527\n",
            "Epoch 20/100, Validation F1: 0.6466\n",
            "Epoch 21/100, Validation F1: 0.6528\n",
            "Epoch 22/100, Validation F1: 0.6488\n",
            "Epoch 23/100, Validation F1: 0.6506\n",
            "Epoch 24/100, Validation F1: 0.6480\n",
            "Epoch 25/100, Validation F1: 0.6510\n",
            "Epoch 26/100, Validation F1: 0.6504\n",
            "Early stopping!\n",
            "Best Validation F1: 0.6542\n",
            "\n",
            "Final Validation F1 Score: 0.6504\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Poor       0.92      0.89      0.90     26387\n",
            "        Poor       0.61      0.70      0.65      6605\n",
            "\n",
            "    accuracy                           0.85     32992\n",
            "   macro avg       0.76      0.79      0.78     32992\n",
            "weighted avg       0.86      0.85      0.85     32992\n",
            "\n",
            "Best Overall Validation F1 Score: 0.6542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make preds on test\n",
        "test_features = test.drop(['id'], axis=1)\n",
        "predictions = make_predictions(best_model, test_features, best_preprocessor, device)\n",
        "\n",
        "# Format the predictions\n",
        "result_df = format_predictions(test, predictions)"
      ],
      "metadata": {
        "id": "yFZ8fYKBciIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = result_df\n",
        "submission.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRpUoboZig9W",
        "outputId": "0ba0c4f5-5cd9-489f-a973-a6fb8a910063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66168, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store\n",
        "submission.to_csv('/content/drive/MyDrive/BDML-2024/P-Set2/submissions/nn_final.csv', index=False)"
      ],
      "metadata": {
        "id": "D63kamjEiqL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6099Pe2HER7",
        "outputId": "306596a6-1466-4b2d-ceaf-cb88a3d919d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66168, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Submission"
      ],
      "metadata": {
        "id": "o-sEubBCpQfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c uniandes-bdml-2024-20-ps-2 -f /content/drive/MyDrive/BDML-2024/P-Set2/submissions/nn_final.csv -m \"neural network tuned FINAL \""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwHkxgNIjum3",
        "outputId": "38ff6f45-dd99-4baa-8c7a-457e5de0cdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 1.70M/1.70M [00:02<00:00, 728kB/s]\n",
            "400 - Bad Request - Submission not allowed:  Your team has used its daily Submission allowance (3) today, please try again tomorrow UTC (22 hours from now).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "def set_kaggle_credentials():\n",
        "    username = input(\"Enter your Kaggle username: \")\n",
        "    key = getpass(\"Enter your Kaggle API key: \")\n",
        "    os.environ['KAGGLE_USERNAME'] = username\n",
        "    os.environ['KAGGLE_KEY'] = key\n",
        "    print(\"Kaggle credentials set as environment variables.\")"
      ],
      "metadata": {
        "id": "4KvRaxsLXr6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Submission File\n",
        "submission_dir = '/content/drive/MyDrive/BDML-2024/P-Set2/submissions/'\n",
        "os.makedirs(submission_dir, exist_ok=True)\n",
        "\n",
        "def create_submission(test_data, predictions, directory, filename='nn_final.csv'):\n",
        "    # Construct full file path\n",
        "    filepath = os.path.join(directory, filename)\n",
        "\n",
        "    # Create the submission DataFrame and save it to the specified path\n",
        "    submission = pd.DataFrame({'id': test_data['id'], 'pobre': predictions})\n",
        "    submission.to_csv(filepath, index=False)\n",
        "    print(f\"Submission saved to {filepath}\")\n",
        "    return filepath  # Return the full file path"
      ],
      "metadata": {
        "id": "vlisPi0kWSxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Submit to Kaggle\n",
        "def submit_to_kaggle(file_path, message):\n",
        "    competition = \"uniandes-bdml-2024-20-ps-2\"\n",
        "    command = f\"kaggle competitions submit -c {competition} -f {file_path} -m \\\"{message}\\\"\"\n",
        "    print(f\"Submitting to Kaggle with command: {command}\")\n",
        "    os.system(command)"
      ],
      "metadata": {
        "id": "XgKVufN0Xisj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Main Execution Flow\n",
        "submission_filename = 'nn_final.csv'\n",
        "submission_file_path = create_submission(test, predictions, submission_dir, submission_filename)\n",
        "print(f\"Submission file path: {submission_file_path}\")\n",
        "\n",
        "# Set credentials and submit to Kaggle\n",
        "set_kaggle_credentials()\n",
        "submit_to_kaggle(submission_file_path, \"neural network with tuned hyperparameters FINAL\")\n",
        "\n",
        "print(\"Submission process completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLGpqRPgYNIB",
        "outputId": "c2776a35-eef6-4e01-f6cc-3bae75cd348d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission saved to /content/drive/MyDrive/BDML-2024/P-Set2/submissions/nn_final.csv\n",
            "Submission file path: /content/drive/MyDrive/BDML-2024/P-Set2/submissions/nn_final.csv\n",
            "Enter your Kaggle username: edmundoariasdeabreu\n",
            "Enter your Kaggle API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Kaggle credentials set as environment variables.\n",
            "Submitting to Kaggle with command: kaggle competitions submit -c uniandes-bdml-2024-20-ps-2 -f /content/drive/MyDrive/BDML-2024/P-Set2/submissions/nn_final.csv -m \"neural network with tuned hyperparameters FINAL\"\n",
            "Submission process completed!\n"
          ]
        }
      ]
    }
  ]
}